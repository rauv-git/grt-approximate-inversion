{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example for General Setting \n",
    "\n",
    "Here, we show an example of how to use the package for general background velocities. Care must be taken that the geometric optics assumption still holds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# Package functions hiding heavy lifting :)\n",
    "from grt_inversion import layered_velocity, bilinear_velocity, one_velocity, extend_and_solve, generate_data_general, plot, compute_tau_and_a\n",
    "from grt_inversion.reconstruction.translation_invariant.data_generation import n_func\n",
    "from grt_inversion.reconstruction.translation_invariant import compute_ref_kernels, interpolate_kernels_fast_safe\n",
    "from grt_inversion.utils import cutoff\n",
    "from grt_inversion.reconstruction.general import compute_kernels_parallel_batched_general\n",
    "\n",
    "\n",
    "SAVE = False\n",
    "LOAD = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup grid data for domain\n",
    "nx, ny = 121, 121\n",
    "a = 6 \n",
    "x, y = np.linspace(-a, a, nx), np.linspace(0, 12, ny)\n",
    "\n",
    "dx = (abs(x[1] - x[0]), abs(y[1] - y[0]))\n",
    "alpha = 5\n",
    "\n",
    "# Choose background velocity\n",
    "# velocity = one_velocity\n",
    "# velocity = layered_velocity\n",
    "velocity = bilinear_velocity\n",
    "\n",
    "# Setup for data space\n",
    "t_data = np.linspace(15, 40, 701)\n",
    "s_data = np.linspace(-10, 10, 111)\n",
    "\n",
    "# Extend domain to include all source/receiver locations for s in s_data\n",
    "ds = s_data[1] - s_data[0]\n",
    "alpha_ind = math.ceil(alpha / ds)\n",
    "\n",
    "s_data_extended = np.linspace(s_data[0] - alpha, s_data[-1] + alpha, len(s_data) + 2*alpha_ind)\n",
    "\n",
    "# Solve eikonal and transport equations for all source locations in s_data_extended\n",
    "tau_vals, a_vals, c = compute_tau_and_a(s_data_extended, x, y, velocity)\n",
    "\n",
    "# Generate data\n",
    "g = generate_data_general(t_data, dx, s_data_extended, s_data, c, alpha, tau_vals, a_vals, x_origin=x[0], func=n_func)\n",
    "\n",
    "# Plot generated data\n",
    "# plot(s_data, t_data, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction parameters for GRT\n",
    "s_vals = s_data # Source positions\n",
    "t_vals = t_data  # Time samples\n",
    "\n",
    "\n",
    "# Reconstruction parameters for reconstruction kernels\n",
    "q, k = 2, 3 \n",
    "gamma = .2\n",
    "\n",
    "# Grid for values p where we determine the reconstruction\n",
    "p1_vals, p2_vals = x, y\n",
    "P1, P2 = np.meshgrid(p1_vals, p2_vals, indexing='ij')\n",
    "p_vals = np.column_stack((P1.ravel(), P2.ravel()))\n",
    "\n",
    "# Generate extended array\n",
    "ds_vals = s_vals[1] - s_vals[0]\n",
    "alpha_ind_vals = math.ceil(alpha / ds_vals)\n",
    "s_vals_extended = np.linspace(s_vals[0] - alpha, s_vals[-1] + alpha, len(s_vals) + 2*alpha_ind_vals)\n",
    "\n",
    "# Compute PDEs for reconstruction kernel grid\n",
    "tau_vals, a_vals, c = compute_tau_and_a(s_vals_extended, x, y, velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute kernel:\n",
    "\n",
    "kernel = compute_kernels_parallel_batched_general(\n",
    "    p_vals, gamma, q, k, t_vals, dx, s_vals_extended, s_vals, c, alpha, tau_vals, a_vals, x[0], batch_size=20\n",
    "    )\n",
    "\n",
    "# Reshape kernel:\n",
    "ref_kernels= kernel.reshape(len(p1_vals), len(p2_vals), len(s_vals), len(t_vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE:\n",
    "    # Save file\n",
    "    filename = f\"ref_kernel.npy\"\n",
    "    np.save(filename, ref_kernels)\n",
    "    print(f\"Saved to: {filename}\")\n",
    "\n",
    "if LOAD:\n",
    "    # Load file\n",
    "    ref_kernels = np.load('ref_kernels.npy')\n",
    "    print(\"kernel loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No interpolation needed - using ref_kernels directly\n"
     ]
    }
   ],
   "source": [
    "if np.any(s_vals != s_data) or np.any(t_vals != t_data):\n",
    "    print(\"Interpolating kernels in parallel...\")\n",
    "    # Automatic selection based on problem size\n",
    "    kernel_data = interpolate_kernels_fast_safe(ref_kernels, s_vals, t_vals, s_data, t_data, n_jobs=-1, method='auto')\n",
    "    print(\"kernels interpolated\")\n",
    "else:\n",
    "    print(\"No interpolation needed - using ref_kernels directly\")\n",
    "    kernel_data = ref_kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take inner products to compute approximate inversion\n",
    "dt = t_data[1] - t_data[0]\n",
    "ds = s_data[1] - s_data[0]\n",
    " \n",
    "result = np.zeros((len(p1_vals), len(p2_vals)))\n",
    "\n",
    "# Apply cutoff function\n",
    "psi_g = sp.csr_matrix(cutoff(g, s_data, t_data))\n",
    "# g = sp.csr_matrix(g)\n",
    "\n",
    "for i in range(len(p1_vals)):\n",
    "    for j in range(len(p2_vals)):\n",
    "        K = sp.csr_matrix(kernel_data[i, j, :, :])\n",
    "        #print(K.shape, g.shape)\n",
    "        if sp.issparse(K):\n",
    "            result[i, j] = ds * dt * np.sum(K.multiply(psi_g))\n",
    "            #result[i, j] = ds * dt * np.sum(K.multiply(g))\n",
    "        else:\n",
    "            result[i, j] = ds * dt  * np.sum(K * psi_g)\n",
    "            #result[i, j] = ds * dt  * np.sum(K * g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot region of interest\n",
    "\n",
    "# Filter the 1D coordinate arrays first\n",
    "p1_mask = (p1_vals >= -5) & (p1_vals <= 5)\n",
    "p2_mask = (p2_vals >= 1) & (p2_vals <= 9)\n",
    "\n",
    "p1_sel = p1_vals[p1_mask]\n",
    "p2_sel = p2_vals[p2_mask]\n",
    "\n",
    "# Slice the result accordingly\n",
    "result_sel = result[np.ix_(p1_mask, p2_mask)]\n",
    "\n",
    "# Create meshgrid for plotting\n",
    "P1, P2 = np.meshgrid(p1_sel, p2_sel, indexing='ij')\n",
    "\n",
    "# Plot\n",
    "\n",
    "with mpl.rc_context({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times\"],  \n",
    "    \"axes.labelsize\": 11,     \n",
    "    \"xtick.labelsize\": 9,\n",
    "    \"ytick.labelsize\": 9,\n",
    "    \"axes.titlesize\": 11,\n",
    "    \"legend.fontsize\": 9,\n",
    "    \"figure.dpi\": 300,       \n",
    "    \"axes.linewidth\": 0.8,    \n",
    "    \"lines.linewidth\": 1.0,\n",
    "    \"lines.markersize\": 4,    \n",
    "    \"text.latex.preamble\": r\"\\usepackage{amsmath,amssymb}\"\n",
    "}):\n",
    "    plt.figure(figsize=(4.5, 3.5))\n",
    "    plt.pcolormesh(P1, P2, result_sel, shading='auto', cmap='Blues')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(r\"$p_1$\")\n",
    "    plt.ylabel(r\"$p_2$\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "approxinv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
